{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be07939b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-26T07:26:01.593836Z",
     "start_time": "2022-07-26T07:26:01.588757Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras import Model, Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.losses import MeanSquaredLogarithmicError\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05ce098",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-26T07:25:40.115527Z",
     "start_time": "2022-07-26T07:25:37.028778Z"
    }
   },
   "source": [
    "### Read data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56820b4a",
   "metadata": {},
   "source": [
    "- To change the data (dataset, size, noise level and noise type), you need to change the variable path. It contains all the information about the dataset e.g.:\n",
    "\n",
    "ClinVarReal_0.3_10000_Sym_KDN_Python.tmp\n",
    "\n",
    "dataset_noiselevel_datasetsize_noisytype_model_implementaion\n",
    "\n",
    "- Model and implementation are not relevant for you"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02e238c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-26T07:38:55.117865Z",
     "start_time": "2022-07-26T07:38:47.475015Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import warnings \n",
    "from time import time\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "import traceback\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "sys.path.insert(0, '../scripts/')\n",
    "\n",
    "#from runRFilter import *\n",
    "#from cleanLabFilter import CleanLab\n",
    "from filtersScikiClean import filtersScikiClean\n",
    "from utils import *\n",
    "from addNoiseScikit import *\n",
    "\n",
    "#path = str(snakemake.output)\n",
    "\n",
    "path = 'temp/ClinVarReal_0.3_1000_Sym_KDN_Python.tmp'\n",
    "\n",
    "st  = path.split('/')[1].split('.tmp')[0].split('_')\n",
    "name = st[0]\n",
    "noiseLevel = float(st[1])\n",
    "datasetSize = int(st[2])\n",
    "noiseType = st[3]\n",
    "model = st[4]\n",
    "imp = st[5]\n",
    "\n",
    "#repeatsrepeatsz = int(snakemake.params.repeats)\n",
    "repeats = 1\n",
    "df = pd.read_csv('../datasets/' + name + '.csv.gz', sep = '\\t',compression='zip',\n",
    "                index_col=None)\n",
    "\n",
    "df = df.fillna(0)\n",
    "ID = [name, model, noiseLevel, noiseType,datasetSize]\n",
    "\n",
    "dfMeansCV = pd.DataFrame()\n",
    "for r in range(repeats):\n",
    "\n",
    "    status = 'F' # F:Failure S: Success N: No noise found\n",
    "\n",
    "    ID = [name, model, noiseLevel, noiseType,datasetSize,r]\n",
    "    X, y, noisyLabels = getData(df,name, noiseType, noiseLevel, datasetSize)\n",
    "    noiseInd = y[y!=noisyLabels].index\n",
    "    dR = pd.DataFrame(np.vstack([X.T, noisyLabels.tolist()]).T)\n",
    "    t0 = time()\n",
    "\n",
    "    \n",
    "    \n",
    "   # if imp=='Python':\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa51c4a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-26T07:38:55.133923Z",
     "start_time": "2022-07-26T07:38:55.119934Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[99,\n",
       " 89,\n",
       " 79,\n",
       " 69,\n",
       " 60,\n",
       " 50,\n",
       " 40,\n",
       " 31,\n",
       " 21,\n",
       " 11,\n",
       " 2,\n",
       " 11,\n",
       " 21,\n",
       " 31,\n",
       " 40,\n",
       " 50,\n",
       " 60,\n",
       " 69,\n",
       " 79,\n",
       " 89,\n",
       " 99]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prepareLayers creates a list with number of layers and noides in each layer\n",
    "# you can change if the ways you want or dont use at all\n",
    "# I needed it to not create a NN for each dataset separetely\n",
    "\n",
    "def prepareLayers(X,n_max=4):\n",
    "    n_output = 2\n",
    "    #print(X.shape[1])\n",
    "    #n_max = 4\n",
    "    nLayers = max(int(X.shape[1]/10),n_max)+1\n",
    "    n = max(round(X.shape[1]),n_max+20)\n",
    "    ns = np.linspace(n_output, n, nLayers,endpoint = False).astype(int)\n",
    "    #layers = [round(X.shape[1])]\n",
    "    ns = list(ns) + [X.shape[1]]\n",
    "    ns = list(reversed(ns))\n",
    "    layers = ns +list(reversed(ns))[1:]\n",
    "    #print(layers)\n",
    "\n",
    "    return layers\n",
    "\n",
    "\n",
    "# mad score is used to compare it with a threshhold and decide about 'outlierness' of a data point \n",
    "def mad_score(points):\n",
    "    \"\"\"https://www.itl.nist.gov/div898/handbook/eda/section3/eda35h.htm \"\"\"\n",
    "    m = np.median(points)\n",
    "    ad = np.abs(points - m)\n",
    "    mad = np.median(ad)\n",
    "    \n",
    "    return 0.6745 * ad / mad\n",
    "\n",
    "\n",
    "prepareLayers(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0cc4071d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-26T07:38:55.152001Z",
     "start_time": "2022-07-26T07:38:55.135503Z"
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "from sklearn.preprocessing import Normalizer, MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\n",
    "from sklearn.preprocessing import Normalizer, MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5801905",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-26T07:39:43.213648Z",
     "start_time": "2022-07-26T07:38:55.153996Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 [100, 91, 82, 73, 64, 55, 46, 37, 28, 19, 10, 2, 10, 19, 28, 37, 46, 55, 64, 73, 82, 91, 100]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-26 09:38:55.200736: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 32>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     63\u001b[0m early_stop \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mEarlyStopping(\n\u001b[1;32m     64\u001b[0m     monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     65\u001b[0m     min_delta\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0001\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     69\u001b[0m     restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     70\u001b[0m )\n\u001b[1;32m     71\u001b[0m cb \u001b[38;5;241m=\u001b[39m [early_stop]\n\u001b[0;32m---> 72\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mautoencoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train_transformed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train_transformed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[43m  \u001b[49m\u001b[38;5;66;43;03m#  validation_data=(X_test_transformed, X_test_transformed),\u001b[39;49;00m\n\u001b[1;32m     79\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\n\u001b[1;32m     80\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m;\n\u001b[1;32m     83\u001b[0m \u001b[38;5;66;03m# pass the transformed test set through the autoencoder to get the reconstructed result\u001b[39;00m\n\u001b[1;32m     84\u001b[0m THRESHOLD \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3.5\u001b[39m\n",
      "File \u001b[0;32m~/work/miniconda/envs/misla1/lib/python3.10/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/work/miniconda/envs/misla1/lib/python3.10/site-packages/keras/engine/training.py:1409\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1402\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1403\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1404\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   1405\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[1;32m   1406\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   1407\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m   1408\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1409\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1410\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1411\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/work/miniconda/envs/misla1/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/work/miniconda/envs/misla1/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/work/miniconda/envs/misla1/lib/python3.10/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/work/miniconda/envs/misla1/lib/python3.10/site-packages/tensorflow/python/eager/function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2450\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   2451\u001b[0m   (graph_function,\n\u001b[1;32m   2452\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2453\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2454\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/work/miniconda/envs/misla1/lib/python3.10/site-packages/tensorflow/python/eager/function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1856\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1857\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1858\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1859\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1860\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1861\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1862\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1863\u001b[0m     args,\n\u001b[1;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1865\u001b[0m     executing_eagerly)\n\u001b[1;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/work/miniconda/envs/misla1/lib/python3.10/site-packages/tensorflow/python/eager/function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    496\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 497\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    503\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    504\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    505\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    506\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    509\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    510\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/work/miniconda/envs/misla1/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# I dont comment the code much because it is takes from here\n",
    "# https://www.kaggle.com/code/robinteuwens/anomaly-detection-with-auto-encoders/notebook\n",
    "\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        #('normalizer', Normalizer()),\n",
    "                     ('scaler', MinMaxScaler())])\n",
    "\n",
    "\n",
    "\n",
    "# here one can decide whether to take the labels as input data (yes) \n",
    "# and whether the labels should be scaled \n",
    "\n",
    "X_temp = X\n",
    "X_temp['Label'] = noisyLabels\n",
    "pipeline.fit(X_temp);\n",
    "#X_transformed = X_temp\n",
    "X_transformed = pipeline.transform(X_temp)\n",
    "\n",
    "#X_transformed = np.column_stack((X_transformed , noisyLabels.values))\n",
    "\n",
    "\n",
    "\n",
    "input_dim = X_temp.shape[1]\n",
    "BATCH_SIZE = 256\n",
    "EPOCHS = 1000\n",
    "\n",
    "\n",
    "\n",
    "ff = []\n",
    "\n",
    "\n",
    "\n",
    "# changing n_max changes the size of the AE, default is 4\n",
    "#for n_max in [1,2,3,4,5,6,7,8,9,10]:\n",
    "for n_max in [4]:\n",
    "    layer_sizes = prepareLayers(X,n_max)\n",
    "    print(n_max,layer_sizes)\n",
    "    X_train_transformed,X_test_transformed, y_train_noisy, y_test_noisy  = train_test_split(X_transformed, noisyLabels,\n",
    "                                           test_size=0.3, \n",
    "                                           random_state=1234)\n",
    "\n",
    "    \n",
    "    \n",
    "    y_test_clean = y[y_test_noisy.index].reset_index(drop = True)\n",
    "    y_train_clean = y[y_train_noisy.index].reset_index(drop = True)\n",
    "    \n",
    "    y_test_noisy = y_test_noisy.reset_index(drop = True)\n",
    "    y_train_noisy = y_train_noisy.reset_index(drop = True)\n",
    "    \n",
    "   # noiseIndTest = y_test_noisy.tr\n",
    "   # noiseIndTrain = y_train_noisy.index\n",
    "    \n",
    "    \n",
    "    autoencoder = tf.keras.models.Sequential(\n",
    "\n",
    "        [tf.keras.layers.Dense(layer_size, activation = 'elu') \n",
    "                                        for layer_size in layer_sizes]\n",
    "\n",
    "    )\n",
    "\n",
    "    # https://keras.io/api/models/model_training_apis/\n",
    "    autoencoder.compile(optimizer=\"adam\", \n",
    "                        loss=\"mse\",\n",
    "                        metrics=[\"acc\"])\n",
    "\n",
    "    early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        min_delta=0.0001,\n",
    "        patience=10,\n",
    "        verbose=0, \n",
    "        mode='min',\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "    cb = [early_stop]\n",
    "    history = autoencoder.fit(\n",
    "        X_train_transformed, X_train_transformed,\n",
    "        shuffle=True,\n",
    "        epochs=EPOCHS,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        callbacks=cb,\n",
    "      #  validation_data=(X_test_transformed, X_test_transformed),\n",
    "        verbose = 0\n",
    "    );\n",
    "     \n",
    "\n",
    "    # pass the transformed test set through the autoencoder to get the reconstructed result\n",
    "    THRESHOLD = 3.5\n",
    "    reconstructions = autoencoder.predict(X_test_transformed)\n",
    "    mse = np.mean(np.power(X_test_transformed - reconstructions, 2), axis=1)\n",
    "    z_scores = mad_score(mse)\n",
    "\n",
    "    noiseInd_test = y_test_clean[y_test_clean!=y_test_noisy].index\n",
    "    foundNoiseInd_test = np.where(z_scores > THRESHOLD)[0]\n",
    "    cm = confusionMatrixScikit(y_test_clean,noiseInd_test,foundNoiseInd_test)[1]\n",
    "    #display(cm)\n",
    "    \n",
    "    #mse = np.mean(np.power(X_test_transformed[:,-1] - reconstructions[:,-1],2))\n",
    "\n",
    "   # noisyLabels = noisyLabels.reset_index(drop = True)\n",
    "   # y = y.reset_index(drop = True)\n",
    "    #clean_test = pd.Series([False]*len(y))\n",
    "    #clean_test[y_test!=noisyLabels]=True\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf580c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Normalizer, MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "import logging\n",
    "\n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from utils import confusionMatrixScikit\n",
    "\n",
    "\n",
    "# prepareLayers creates a list with number of layers and noides in each layer\n",
    "# you can change if the ways you want or dont use at all\n",
    "# I needed it to not create a NN for each dataset separetely\n",
    "\n",
    "def prepareLayers(X,n_max=4):\n",
    "    # n_max regulates the size of the AE\n",
    "    n_output = 2\n",
    "    nLayers = max(int(X.shape[1]/10),n_max)+1\n",
    "    n = max(round(X.shape[1]),n_max+20)\n",
    "    ns = np.linspace(n_output, n, nLayers,endpoint = False).astype(int)\n",
    "    ns = list(ns) + [X.shape[1]]\n",
    "    ns = list(reversed(ns))\n",
    "    layers = ns +list(reversed(ns))[1:]\n",
    "\n",
    "    return layers\n",
    "\n",
    "# mad score is used to compare it with a threshhold and decide about 'outlierness' of a data point \n",
    "def mad_score(points):\n",
    "    \"\"\"https://www.itl.nist.gov/div898/handbook/eda/section3/eda35h.htm \"\"\"\n",
    "    m = np.median(points)\n",
    "    ad = np.abs(points - m)\n",
    "    mad = np.median(ad)\n",
    "    \n",
    "    return 0.6745 * ad / mad\n",
    "\n",
    "\n",
    "# returns the index of instances that could be noisy (foundNoiseInd) and the confusion matrix \n",
    "def compute_cm(THRESHOLD,reconstructions, X, y_noisy, y_clean):\n",
    "    #THRESHOLD = 3.5\n",
    "    noiseInd = y_noisy[y_noisy!=y_clean].index\n",
    "    #reconstructions = autoencoder.predict(X,verbose = 0)\n",
    "    mse = np.mean(np.power(X - reconstructions, 2), axis=1)\n",
    "    z_scores = mad_score(mse)\n",
    "\n",
    "    noiseInd = y_clean[y_clean!=y_noisy].index\n",
    "    foundNoiseInd = np.where(z_scores > THRESHOLD)[0]\n",
    "    cm = confusionMatrixScikit(y_clean,noiseInd,foundNoiseInd)[1]\n",
    "    cm['Retrieved'] = (len(foundNoiseInd)/reconstructions.shape[0])\n",
    "    return foundNoiseInd, cm\n",
    "\n",
    "\n",
    "def AEFilter(X,noisyLabels,y):\n",
    "    ## https://www.kaggle.com/code/robinteuwens/anomaly-detection-with-auto-encoders/notebook\n",
    "    pipeline = Pipeline(\n",
    "        [\n",
    "            #('normalizer', Normalizer()),\n",
    "                         ('scaler', MinMaxScaler())])\n",
    "\n",
    "   \n",
    "\n",
    "    # here one can decide whether to take the labels as input data (yes) \n",
    "    # and whether the labels should be scaled \n",
    "    X_temp = X\n",
    "    X_temp['Label'] = noisyLabels\n",
    "    pipeline.fit(X_temp);\n",
    "    #X_transformed = X_temp\n",
    "    X_transformed = pipeline.transform(X_temp)\n",
    "    #X_transformed = np.column_stack((X_transformed , noisyLabels.values))\n",
    "\n",
    "\n",
    "    input_dim = X_temp.shape[1]\n",
    "    BATCH_SIZE = 256\n",
    "    EPOCHS = 1000\n",
    "    ff = []\n",
    "    n_max = 4\n",
    "    layer_sizes = prepareLayers(X,n_max)\n",
    "    \n",
    "    print(n_max,layer_sizes)\n",
    "    X_train_transformed,X_test_transformed, y_train_noisy, y_test_noisy  = train_test_split(X_transformed, noisyLabels,\n",
    "                                           test_size=0.3, \n",
    "                                           random_state=1234)\n",
    "\n",
    "\n",
    "\n",
    "    y_test_clean = y[y_test_noisy.index].reset_index(drop = True)\n",
    "    y_train_clean = y[y_train_noisy.index].reset_index(drop = True)\n",
    "\n",
    "    y_test_noisy = y_test_noisy.reset_index(drop = True)\n",
    "    y_train_noisy = y_train_noisy.reset_index(drop = True)\n",
    "\n",
    "   # noiseIndTest = y_test_noisy.tr\n",
    "   # noiseIndTrain = y_train_noisy.index\n",
    "\n",
    "\n",
    "    autoencoder = tf.keras.models.Sequential(\n",
    "\n",
    "        [tf.keras.layers.Dense(layer_size, activation = 'elu') \n",
    "                                        for layer_size in layer_sizes]\n",
    "\n",
    "    )\n",
    "\n",
    "    # https://keras.io/api/models/model_training_apis/\n",
    "    autoencoder.compile(optimizer=\"adam\", \n",
    "                        loss=\"mse\",\n",
    "                        metrics=[\"acc\"])\n",
    "\n",
    "    early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='loss',\n",
    "        min_delta=0.0001,\n",
    "        patience=10,\n",
    "        verbose=0, \n",
    "        mode='min',\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "    cb = [early_stop]\n",
    "    history = autoencoder.fit(\n",
    "        X_train_transformed, X_train_transformed,\n",
    "        shuffle=True,\n",
    "        epochs=EPOCHS,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        callbacks=cb,\n",
    "      #  validation_data=(X_test_transformed, X_test_transformed),\n",
    "        verbose = 0\n",
    "    );\n",
    "\n",
    "\n",
    "    # pass the transformed test set through the autoencoder to get the reconstructed result\n",
    "    th = 1\n",
    "    reconstructions = autoencoder.predict(X_transformed, verbose = 0)\n",
    "    foundNoiseInd, cm = compute_cm(th,reconstructions = reconstructions, X = X_transformed, y_noisy = noisyLabels, y_clean = y)\n",
    "    \n",
    "    cms = pd.DataFrame()\n",
    "    li = [0.2,0.5,1,2,3,4,5,6,7,8,9,10]\n",
    "    li = list(np.linspace(0,15,30))\n",
    "    #li = [6]\n",
    "    \n",
    "    reconstructions = autoencoder.predict(X_test_transformed, verbose = 0)\n",
    "\n",
    "    for th in li:   \n",
    "        \n",
    "        cm = compute_cm(th,reconstructions = reconstructions, X = X_test_transformed, y_noisy = y_test_noisy, y_clean = y_test_clean)[1]\n",
    "        cms = cms.append(cm)\n",
    "    cms.index = li\n",
    "    \n",
    "    return pd.Series(foundNoiseInd), cms.to_dict()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "55f03aa5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-23T11:54:33.116382Z",
     "start_time": "2022-07-23T11:54:33.112054Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_cm(THRESHOLD, X, y_noisy, y_clean):\n",
    "    noiseInd = y_noisy[y_noisy!=y_clean].index\n",
    "    reconstructions = autoencoder.predict(X,verbose = 0)\n",
    "    mse = np.mean(np.power(X - reconstructions, 2), axis=1)\n",
    "    z_scores = mad_score(mse)\n",
    "\n",
    "    noiseInd = y_clean[y_clean!=y_noisy].index\n",
    "    foundNoiseInd = np.where(z_scores > THRESHOLD)[0]\n",
    "    cm = confusionMatrixScikit(y_clean,noiseInd,foundNoiseInd)[1]\n",
    "    cm['Retrieved'] = (len(foundNoiseInd)/reconstructions.shape[0])\n",
    "    return foundNoiseInd, cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "60f4a2bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-23T11:54:33.204735Z",
     "start_time": "2022-07-23T11:54:33.118845Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F-score</th>\n",
       "      <th>Retrieved</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.303318</td>\n",
       "      <td>0.426667</td>\n",
       "      <td>0.354571</td>\n",
       "      <td>0.422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Precision    Recall   F-score  Retrieved\n",
       "0   0.303318  0.426667  0.354571      0.422"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_cm(THRESHOLD = 0.8, X = X_transformed, y_noisy = noisyLabels, y_clean = y)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "53d2f5b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-23T11:54:35.304827Z",
     "start_time": "2022-07-23T11:54:33.206214Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F-score</th>\n",
       "      <th>Retrieved</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.000000</th>\n",
       "      <td>0.300000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.241379</th>\n",
       "      <td>0.308434</td>\n",
       "      <td>0.853333</td>\n",
       "      <td>0.453097</td>\n",
       "      <td>0.830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.482759</th>\n",
       "      <td>0.316514</td>\n",
       "      <td>0.690000</td>\n",
       "      <td>0.433962</td>\n",
       "      <td>0.654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.724138</th>\n",
       "      <td>0.302575</td>\n",
       "      <td>0.470000</td>\n",
       "      <td>0.368146</td>\n",
       "      <td>0.466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.965517</th>\n",
       "      <td>0.289809</td>\n",
       "      <td>0.303333</td>\n",
       "      <td>0.296417</td>\n",
       "      <td>0.314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.206897</th>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.183333</td>\n",
       "      <td>0.220884</td>\n",
       "      <td>0.198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.448276</th>\n",
       "      <td>0.293333</td>\n",
       "      <td>0.146667</td>\n",
       "      <td>0.195556</td>\n",
       "      <td>0.150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.689655</th>\n",
       "      <td>0.282051</td>\n",
       "      <td>0.110000</td>\n",
       "      <td>0.158273</td>\n",
       "      <td>0.117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.931034</th>\n",
       "      <td>0.306931</td>\n",
       "      <td>0.103333</td>\n",
       "      <td>0.154613</td>\n",
       "      <td>0.101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.172414</th>\n",
       "      <td>0.337209</td>\n",
       "      <td>0.096667</td>\n",
       "      <td>0.150259</td>\n",
       "      <td>0.086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.413793</th>\n",
       "      <td>0.343284</td>\n",
       "      <td>0.076667</td>\n",
       "      <td>0.125341</td>\n",
       "      <td>0.067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.655172</th>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.896552</th>\n",
       "      <td>0.326087</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.086705</td>\n",
       "      <td>0.046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.137931</th>\n",
       "      <td>0.314286</td>\n",
       "      <td>0.036667</td>\n",
       "      <td>0.065672</td>\n",
       "      <td>0.035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.379310</th>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.026667</td>\n",
       "      <td>0.049080</td>\n",
       "      <td>0.026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.620690</th>\n",
       "      <td>0.260870</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.037152</td>\n",
       "      <td>0.023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.862069</th>\n",
       "      <td>0.260870</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.037152</td>\n",
       "      <td>0.023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.103448</th>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.031153</td>\n",
       "      <td>0.021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.344828</th>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.031348</td>\n",
       "      <td>0.019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.586207</th>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.025397</td>\n",
       "      <td>0.015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.827586</th>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.025559</td>\n",
       "      <td>0.013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.068966</th>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.025723</td>\n",
       "      <td>0.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.310345</th>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.025723</td>\n",
       "      <td>0.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.551724</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.019417</td>\n",
       "      <td>0.009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.793103</th>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.019481</td>\n",
       "      <td>0.008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.034483</th>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.019544</td>\n",
       "      <td>0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.275862</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>0.013072</td>\n",
       "      <td>0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.517241</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>0.013072</td>\n",
       "      <td>0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.758621</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>0.013115</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.000000</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>0.013115</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Precision    Recall   F-score  Retrieved\n",
       "0.000000   0.300000  1.000000  0.461538      1.000\n",
       "0.241379   0.308434  0.853333  0.453097      0.830\n",
       "0.482759   0.316514  0.690000  0.433962      0.654\n",
       "0.724138   0.302575  0.470000  0.368146      0.466\n",
       "0.965517   0.289809  0.303333  0.296417      0.314\n",
       "1.206897   0.277778  0.183333  0.220884      0.198\n",
       "1.448276   0.293333  0.146667  0.195556      0.150\n",
       "1.689655   0.282051  0.110000  0.158273      0.117\n",
       "1.931034   0.306931  0.103333  0.154613      0.101\n",
       "2.172414   0.337209  0.096667  0.150259      0.086\n",
       "2.413793   0.343284  0.076667  0.125341      0.067\n",
       "2.655172   0.368421  0.070000  0.117647      0.057\n",
       "2.896552   0.326087  0.050000  0.086705      0.046\n",
       "3.137931   0.314286  0.036667  0.065672      0.035\n",
       "3.379310   0.307692  0.026667  0.049080      0.026\n",
       "3.620690   0.260870  0.020000  0.037152      0.023\n",
       "3.862069   0.260870  0.020000  0.037152      0.023\n",
       "4.103448   0.238095  0.016667  0.031153      0.021\n",
       "4.344828   0.263158  0.016667  0.031348      0.019\n",
       "4.586207   0.266667  0.013333  0.025397      0.015\n",
       "4.827586   0.307692  0.013333  0.025559      0.013\n",
       "5.068966   0.363636  0.013333  0.025723      0.011\n",
       "5.310345   0.363636  0.013333  0.025723      0.011\n",
       "5.551724   0.333333  0.010000  0.019417      0.009\n",
       "5.793103   0.375000  0.010000  0.019481      0.008\n",
       "6.034483   0.428571  0.010000  0.019544      0.007\n",
       "6.275862   0.333333  0.006667  0.013072      0.006\n",
       "6.517241   0.333333  0.006667  0.013072      0.006\n",
       "6.758621   0.400000  0.006667  0.013115      0.005\n",
       "7.000000   0.400000  0.006667  0.013115      0.005"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dryBean : 1\n",
    "# Adult: 3.6,\n",
    "cms = pd.DataFrame()\n",
    "li = [0.2,0.5,1,2,3,4,5,6,7,8,9,10]\n",
    "li = list(np.linspace(0,7,30))\n",
    "#li = list(np.linspace(0.5,2,10))\n",
    "for THRESHOLD in li:   \n",
    "    cm = compute_cm(THRESHOLD, X = X_transformed, y_noisy = noisyLabels, y_clean = y)[1]\n",
    "    cms = cms.append(cm)\n",
    "cms.index = li\n",
    "    #display(cm)\n",
    "cms    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8aeb02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fffca5e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "eb4b2610",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-23T11:45:55.938827Z",
     "start_time": "2022-07-23T11:45:54.803574Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F-score</th>\n",
       "      <th>Retrieved</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.000000</th>\n",
       "      <td>0.226667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.369565</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.517241</th>\n",
       "      <td>0.206349</td>\n",
       "      <td>0.573529</td>\n",
       "      <td>0.303502</td>\n",
       "      <td>0.630000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.034483</th>\n",
       "      <td>0.240964</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.264901</td>\n",
       "      <td>0.276667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.551724</th>\n",
       "      <td>0.241935</td>\n",
       "      <td>0.220588</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.206667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.068966</th>\n",
       "      <td>0.229167</td>\n",
       "      <td>0.161765</td>\n",
       "      <td>0.189655</td>\n",
       "      <td>0.160000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.586207</th>\n",
       "      <td>0.244444</td>\n",
       "      <td>0.161765</td>\n",
       "      <td>0.194690</td>\n",
       "      <td>0.150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.103448</th>\n",
       "      <td>0.225000</td>\n",
       "      <td>0.132353</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.133333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.620690</th>\n",
       "      <td>0.194444</td>\n",
       "      <td>0.102941</td>\n",
       "      <td>0.134615</td>\n",
       "      <td>0.120000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.137931</th>\n",
       "      <td>0.212121</td>\n",
       "      <td>0.102941</td>\n",
       "      <td>0.138614</td>\n",
       "      <td>0.110000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.655172</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0.122449</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.172414</th>\n",
       "      <td>0.192308</td>\n",
       "      <td>0.073529</td>\n",
       "      <td>0.106383</td>\n",
       "      <td>0.086667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.689655</th>\n",
       "      <td>0.227273</td>\n",
       "      <td>0.073529</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.073333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.206897</th>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.073529</td>\n",
       "      <td>0.114943</td>\n",
       "      <td>0.063333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.724138</th>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.096386</td>\n",
       "      <td>0.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.241379</th>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.098765</td>\n",
       "      <td>0.043333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.758621</th>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.044118</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>0.040000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8.275862</th>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.044118</td>\n",
       "      <td>0.078947</td>\n",
       "      <td>0.026667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8.793103</th>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.044118</td>\n",
       "      <td>0.078947</td>\n",
       "      <td>0.026667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.310345</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.044118</td>\n",
       "      <td>0.081081</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.827586</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.044118</td>\n",
       "      <td>0.081081</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.344828</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.044118</td>\n",
       "      <td>0.081081</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.862069</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.054795</td>\n",
       "      <td>0.016667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11.379310</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.054795</td>\n",
       "      <td>0.016667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11.896552</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.054795</td>\n",
       "      <td>0.016667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12.413793</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.054795</td>\n",
       "      <td>0.016667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12.931034</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.054795</td>\n",
       "      <td>0.016667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13.448276</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.054795</td>\n",
       "      <td>0.016667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13.965517</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.054795</td>\n",
       "      <td>0.016667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14.482759</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.054795</td>\n",
       "      <td>0.016667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15.000000</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.054795</td>\n",
       "      <td>0.016667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Precision    Recall   F-score  Retrieved\n",
       "0.000000    0.226667  1.000000  0.369565   1.000000\n",
       "0.517241    0.206349  0.573529  0.303502   0.630000\n",
       "1.034483    0.240964  0.294118  0.264901   0.276667\n",
       "1.551724    0.241935  0.220588  0.230769   0.206667\n",
       "2.068966    0.229167  0.161765  0.189655   0.160000\n",
       "2.586207    0.244444  0.161765  0.194690   0.150000\n",
       "3.103448    0.225000  0.132353  0.166667   0.133333\n",
       "3.620690    0.194444  0.102941  0.134615   0.120000\n",
       "4.137931    0.212121  0.102941  0.138614   0.110000\n",
       "4.655172    0.200000  0.088235  0.122449   0.100000\n",
       "5.172414    0.192308  0.073529  0.106383   0.086667\n",
       "5.689655    0.227273  0.073529  0.111111   0.073333\n",
       "6.206897    0.263158  0.073529  0.114943   0.063333\n",
       "6.724138    0.266667  0.058824  0.096386   0.050000\n",
       "7.241379    0.307692  0.058824  0.098765   0.043333\n",
       "7.758621    0.250000  0.044118  0.075000   0.040000\n",
       "8.275862    0.375000  0.044118  0.078947   0.026667\n",
       "8.793103    0.375000  0.044118  0.078947   0.026667\n",
       "9.310345    0.500000  0.044118  0.081081   0.020000\n",
       "9.827586    0.500000  0.044118  0.081081   0.020000\n",
       "10.344828   0.500000  0.044118  0.081081   0.020000\n",
       "10.862069   0.400000  0.029412  0.054795   0.016667\n",
       "11.379310   0.400000  0.029412  0.054795   0.016667\n",
       "11.896552   0.400000  0.029412  0.054795   0.016667\n",
       "12.413793   0.400000  0.029412  0.054795   0.016667\n",
       "12.931034   0.400000  0.029412  0.054795   0.016667\n",
       "13.448276   0.400000  0.029412  0.054795   0.016667\n",
       "13.965517   0.400000  0.029412  0.054795   0.016667\n",
       "14.482759   0.400000  0.029412  0.054795   0.016667\n",
       "15.000000   0.400000  0.029412  0.054795   0.016667"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cms = pd.DataFrame()\n",
    "li = [0.2,0.5,1,2,3,4,5,6,7,8,9,10]\n",
    "li = list(np.linspace(0,15,30))\n",
    "#li = [6]\n",
    "for THRESHOLD in li:   \n",
    "    reconstructions = autoencoder.predict(X_test_transformed,verbose=0)\n",
    "    mse = np.mean(np.power(X_test_transformed - reconstructions, 2), axis=1)\n",
    "    z_scores = mad_score(mse)\n",
    "\n",
    "    noiseInd_test = y_test_clean[y_test_clean!=y_test_noisy].index\n",
    "    foundNoiseInd_test = np.where(z_scores > THRESHOLD)[0]\n",
    "    cm = confusionMatrixScikit(y_test_clean,noiseInd_test,foundNoiseInd_test)[1]\n",
    "    cm['Retrieved'] = (len(foundNoiseInd_test)/reconstructions.shape[0])\n",
    "    cms = cms.append(cm)\n",
    "cms.index = li\n",
    "    #display(cm)\n",
    "cms    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1d6746",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f45086d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7769a208",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbae199b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-22T09:20:31.290054Z",
     "start_time": "2022-07-22T09:20:31.203617Z"
    }
   },
   "outputs": [],
   "source": [
    "for THRESHOLD in [2.5,3,3.5]:\n",
    "#[3.5,0.5,1,2,3,4,5,6,7,8,9,10]:\n",
    "    z_scores = mad_score(mse)\n",
    "    outliers = z_scores > THRESHOLD\n",
    "    print(f\"Detected {np.sum(outliers):,} outliers in a total of {np.size(z_scores):,} observations [{np.sum(outliers)/np.size(z_scores):.2%}].\")\n",
    "\n",
    "    foundNoiseInd = X[outliers].index.to_list()\n",
    "    display(pd.crosstab(pd.Series(outliers),clean))\n",
    "    #acc = accuracy_score(clean, outliers)\n",
    "    #print(THRESHOLD, acc)\n",
    "\n",
    "    f = clean[outliers].sum()\n",
    "    fff = [n_max,THRESHOLD,f,outliers.sum(),round(f/outliers.sum(),3)]\n",
    "    print(fff)\n",
    "    ff.append(fff)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a574b44",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-22T08:00:08.591513Z",
     "start_time": "2022-07-22T08:00:08.586369Z"
    }
   },
   "outputs": [],
   "source": [
    "y_test_noisy.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd4d276",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-22T08:01:31.427050Z",
     "start_time": "2022-07-22T08:01:31.422134Z"
    }
   },
   "outputs": [],
   "source": [
    "y_test_clean = y[y_test_noisy.index]\n",
    "y_train_clean = y[y_train_noisy.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da3baf5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-22T08:01:45.573656Z",
     "start_time": "2022-07-22T08:01:45.557943Z"
    }
   },
   "outputs": [],
   "source": [
    "y_test_clean\n",
    "y_train_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d56e01",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-16T12:29:37.797367Z",
     "start_time": "2022-06-16T12:29:37.572287Z"
    }
   },
   "outputs": [],
   "source": [
    "#mse = np.mean(np.power(X_test_transformed - reconstructions, 2), axis=1)\n",
    "pd.DataFrame([list(X_test_transformed[:,-1]),X.iloc[:,-1].values]).T\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbd0d40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4564c3c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-22T07:41:57.577817Z",
     "start_time": "2022-07-22T07:41:57.569810Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.Series(mse).round(3).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa29eb71",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-22T07:45:56.136288Z",
     "start_time": "2022-07-22T07:45:56.126156Z"
    }
   },
   "outputs": [],
   "source": [
    "clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdff3a2c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-22T07:42:50.564254Z",
     "start_time": "2022-07-22T07:42:50.362858Z"
    }
   },
   "outputs": [],
   "source": [
    "mse = np.power(X_test_transformed[:,-1] - reconstructions[:,-1],2)\n",
    "#mse = np.mean(np.power(X_test_transformed[:,-1] - reconstructions[:,-1],2))\n",
    "\n",
    "noisyLabels = noisyLabels#.reset_index(drop = True)\n",
    "y = y#.reset_index(drop = True)\n",
    "clean = pd.Series([False]*len(y))\n",
    "clean[y!=noisyLabels]=True\n",
    "\n",
    "for THRESHOLD in [0.2,0.5,1,2,3,3.5,4,5,6,7,8,9,10]:\n",
    "    z_scores = mad_score(mse)\n",
    "    outliers = z_scores > THRESHOLD\n",
    "   # print(THRESHOLD)\n",
    "    print(f\"Detected {np.sum(outliers):,} outliers in a total of {np.size(z_scores):,} observations [{np.sum(outliers)/np.size(z_scores):.2%}].\")\n",
    "\n",
    "    foundNoiseInd = X[outliers].index.to_list()\n",
    "   # display(pd.crosstab(pd.Series(outliers),clean))\n",
    "    #acc = accuracy_score(clean, outliers)\n",
    "    #print(THRESHOLD, acc)\n",
    "    cm = confusionMatrixScikit(y,noiseInd,foundNoiseInd)[1]\n",
    "    display(cm)\n",
    "\n",
    "    f = clean[outliers].sum()\n",
    "    fff = [n_max,THRESHOLD,f,outliers.sum(),round(f/outliers.sum(),3)]\n",
    "    #print(fff)\n",
    "    ff.append(fff)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2d5355",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-22T07:44:48.505294Z",
     "start_time": "2022-07-22T07:44:47.750949Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "X_test_transformed = X_transformed\n",
    "\n",
    "# pass the transformed test set through the autoencoder to get the reconstructed result\n",
    "reconstructions = autoencoder.predict(X_test_transformed)\n",
    "mse = np.mean(np.power(X_test_transformed - reconstructions, 2), axis=1)\n",
    "THRESHOLD = 3.5\n",
    "\n",
    "z_scores = mad_score(mse)\n",
    "outliers = z_scores > THRESHOLD\n",
    "print(f\"Detected {np.sum(outliers):,} outliers in a total of {np.size(z_scores):,} observations [{np.sum(outliers)/np.size(z_scores):.2%}].\")\n",
    "\n",
    "foundNoiseInd = X[outliers].index.to_list()\n",
    "#display(pd.crosstab(pd.Series(outliers),clean))\n",
    "#acc = accuracy_score(clean, outliers)\n",
    "#foundNoiseInd = AEFilter(X,noisyLabels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f6dff4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-15T16:36:44.281112Z",
     "start_time": "2022-06-15T16:36:44.272300Z"
    }
   },
   "outputs": [],
   "source": [
    "noisyLabels = noisyLabels.reset_index(drop = True)\n",
    "y = y.reset_index(drop = True)\n",
    "clean = pd.Series([False]*len(y))\n",
    "clean[y!=noisyLabels]=True\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8617c8c6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-15T16:36:44.969959Z",
     "start_time": "2022-06-15T16:36:44.965195Z"
    }
   },
   "outputs": [],
   "source": [
    "outliers.sum()\n",
    "#len(outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73a51ee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-15T16:36:45.390002Z",
     "start_time": "2022-06-15T16:36:45.384131Z"
    }
   },
   "outputs": [],
   "source": [
    "clean[outliers].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272f3bed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-15T15:40:50.366500Z",
     "start_time": "2022-06-15T15:40:50.360617Z"
    }
   },
   "outputs": [],
   "source": [
    "(outliers==clean).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d987dcca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-15T18:51:24.241843Z",
     "start_time": "2022-06-15T18:51:23.835467Z"
    }
   },
   "outputs": [],
   "source": [
    "X_test_transformed = pipeline.transform(X)\n",
    "\n",
    "# pass the transformed test set through the autoencoder to get the reconstructed result\n",
    "reconstructions = autoencoder.predict(X_test_transformed)\n",
    "\n",
    "def mad_score(points):\n",
    "    \"\"\"https://www.itl.nist.gov/div898/handbook/eda/section3/eda35h.htm \"\"\"\n",
    "    m = np.median(points)\n",
    "    ad = np.abs(points - m)\n",
    "    mad = np.median(ad)\n",
    "    \n",
    "    return 0.6745 * ad / mad\n",
    "\n",
    "\n",
    "\n",
    "mse = np.mean(np.power(X_test_transformed - reconstructions, 2), axis=1)\n",
    "\n",
    "\n",
    "noisyLabels = noisyLabels.reset_index(drop = True)\n",
    "y = y.reset_index(drop = True)\n",
    "clean = pd.Series([False]*len(y))\n",
    "clean[y!=noisyLabels]=True\n",
    "from sklearn.metrics import accuracy_score\n",
    "THRESHOLD = 5\n",
    "for THRESHOLD in [2.5,3,3.5]:\n",
    "#[3.5,0.5,1,2,3,4,5,6,7,8,9,10]:\n",
    "    z_scores = mad_score(mse)\n",
    "    outliers = z_scores > THRESHOLD\n",
    "    print(f\"Detected {np.sum(outliers):,} outliers in a total of {np.size(z_scores):,} observations [{np.sum(outliers)/np.size(z_scores):.2%}].\")\n",
    "\n",
    "    foundNoiseInd = X[outliers].index.to_list()\n",
    "    display(pd.crosstab(pd.Series(outliers),clean))\n",
    "    acc = accuracy_score(clean, outliers)\n",
    "    print(THRESHOLD, acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8355300a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-22T10:10:46.431694Z",
     "start_time": "2022-07-22T10:10:46.418418Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Normalizer, MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def prepareLayers(X,n_max=4):\n",
    "    n_output = 2\n",
    "    #print(X.shape[1])\n",
    "    #n_max = 4\n",
    "    nLayers = max(int(X.shape[1]/10),n_max)+1\n",
    "    n = max(round(X.shape[1]),n_max+20)\n",
    "    ns = np.linspace(n_output, n, nLayers,endpoint = False).astype(int)\n",
    "    #layers = [round(X.shape[1])]\n",
    "    ns = list(ns) + [X.shape[1]]\n",
    "    ns = list(reversed(ns))\n",
    "    layers = ns +list(reversed(ns))[1:]\n",
    "    #print(layers)\n",
    "\n",
    "    return layers\n",
    "\n",
    "def mad_score(points):\n",
    "    \"\"\"https://www.itl.nist.gov/div898/handbook/eda/section3/eda35h.htm \"\"\"\n",
    "    m = np.median(points)\n",
    "    ad = np.abs(points - m)\n",
    "    mad = np.median(ad)\n",
    "    \n",
    "    return 0.6745 * ad / mad\n",
    "\n",
    "\n",
    "def compute_cm(THRESHOLD,reconstructions, X, y_noisy, y_clean):\n",
    "    #THRESHOLD = 3.5\n",
    "    noiseInd = y_noisy[y_noisy!=y_clean].index\n",
    "    #reconstructions = autoencoder.predict(X,verbose = 0)\n",
    "    mse = np.mean(np.power(X - reconstructions, 2), axis=1)\n",
    "    z_scores = mad_score(mse)\n",
    "\n",
    "    noiseInd = y_clean[y_clean!=y_noisy].index\n",
    "    foundNoiseInd = np.where(z_scores > THRESHOLD)[0]\n",
    "    cm = confusionMatrixScikit(y_clean,noiseInd,foundNoiseInd)[1]\n",
    "    cm['Retrieved'] = (len(foundNoiseInd)/reconstructions.shape[0])\n",
    "    return foundNoiseInd, cm\n",
    "\n",
    "\n",
    "def AEFilter(X,noisyLabels,y):\n",
    "    ## https://www.kaggle.com/code/robinteuwens/anomaly-detection-with-auto-encoders/notebook\n",
    "\n",
    "    y =  y.reset_index(drop = True)\n",
    "    noisyLabels = noisyLabels.reset_index(drop = True)\n",
    "    X = X.reset_index(drop = True)\n",
    "\n",
    "\n",
    "\n",
    "    pipeline = Pipeline(\n",
    "        [\n",
    "            #('normalizer', Normalizer()),\n",
    "                         ('scaler', MinMaxScaler())])\n",
    "\n",
    "    input_dim = X.shape[1]\n",
    "    BATCH_SIZE = 256\n",
    "    EPOCHS = 1000\n",
    "\n",
    "    X_temp = X\n",
    "\n",
    "    X_temp['Label'] = noisyLabels\n",
    "\n",
    "    pipeline.fit(X_temp);\n",
    "    #X_transformed = X_temp\n",
    "    X_transformed = pipeline.transform(X_temp)\n",
    "\n",
    "    #X_transformed = np.column_stack((X_transformed , noisyLabels.values))\n",
    "\n",
    "\n",
    "    #X_transformed = X.values\n",
    "    ff = []\n",
    "    #n_max in [1,2,3,4,5,6,7,8,9,10]:\n",
    "    n_max = 4\n",
    "    layer_sizes = prepareLayers(X,n_max)\n",
    "    #layer_sizes = ns + list(reversed(ns))[1:]\n",
    "    print(n_max,layer_sizes)\n",
    "    # train // validate - no labels since they're all clean anyway\n",
    "    X_train_transformed,X_test_transformed, y_train_noisy, y_test_noisy  = train_test_split(X_transformed, noisyLabels,\n",
    "                                           test_size=0.3, \n",
    "                                           random_state=1234)\n",
    "\n",
    "\n",
    "\n",
    "    y_test_clean = y[y_test_noisy.index].reset_index(drop = True)\n",
    "    y_train_clean = y[y_train_noisy.index].reset_index(drop = True)\n",
    "\n",
    "    y_test_noisy = y_test_noisy.reset_index(drop = True)\n",
    "    y_train_noisy = y_train_noisy.reset_index(drop = True)\n",
    "\n",
    "   # noiseIndTest = y_test_noisy.tr\n",
    "   # noiseIndTrain = y_train_noisy.index\n",
    "\n",
    "\n",
    "    autoencoder = tf.keras.models.Sequential(\n",
    "\n",
    "        [tf.keras.layers.Dense(layer_size, activation = 'elu') \n",
    "                                        for layer_size in layer_sizes]\n",
    "\n",
    "    )\n",
    "\n",
    "    # https://keras.io/api/models/model_training_apis/\n",
    "    autoencoder.compile(optimizer=\"adam\", \n",
    "                        loss=\"mse\",\n",
    "                        metrics=[\"acc\"])\n",
    "\n",
    "    early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='loss',\n",
    "        min_delta=0.0001,\n",
    "        patience=10,\n",
    "        verbose=0, \n",
    "        mode='min',\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "    cb = [early_stop]\n",
    "    history = autoencoder.fit(\n",
    "        X_train_transformed, X_train_transformed,\n",
    "        shuffle=True,\n",
    "        epochs=EPOCHS,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        callbacks=cb,\n",
    "      #  validation_data=(X_test_transformed, X_test_transformed),\n",
    "        verbose = 0\n",
    "    );\n",
    "\n",
    "\n",
    "    # pass the transformed test set through the autoencoder to get the reconstructed result\n",
    "    th = 3.5\n",
    "    reconstructions = autoencoder.predict(X_transformed, verbose = 0)\n",
    "    foundNoiseInd, cm = compute_cm(th,reconstructions = reconstructions, X = X_transformed, y_noisy = noisyLabels, y_clean = y)\n",
    "    \n",
    "    cms = pd.DataFrame()\n",
    "    li = [0.2,0.5,1,2,3,4,5,6,7,8,9,10]\n",
    "    li = list(np.linspace(0,15,30))\n",
    "    #li = [6]\n",
    "    \n",
    "    reconstructions = autoencoder.predict(X_test_transformed, verbose = 0)\n",
    "\n",
    "    for th in li:   \n",
    "        \n",
    "        cm = compute_cm(th,reconstructions = reconstructions, X = X_test_transformed, y_noisy = y_test_noisy, y_clean = y_test_clean)[1]\n",
    "        cms = cms.append(cm)\n",
    "    cms.index = li\n",
    "    \n",
    "    return foundNoiseInd, cms\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d28890c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-22T10:10:49.639817Z",
     "start_time": "2022-07-22T10:10:46.856682Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 [17, 19, 15, 10, 6, 2, 6, 10, 15, 19, 17]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-22 12:10:46.875463: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "foundNoiseInd, cms = AEFilter(X,noisyLabels,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f770569",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-22T10:10:56.657882Z",
     "start_time": "2022-07-22T10:10:56.652433Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      12\n",
       "1      26\n",
       "2      53\n",
       "3      60\n",
       "4      65\n",
       "     ... \n",
       "87    989\n",
       "88    990\n",
       "89    991\n",
       "90    996\n",
       "91    999\n",
       "Length: 92, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(foundNoiseInd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c12e05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:misla1]",
   "language": "python",
   "name": "conda-env-misla1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
